{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/intake/source/discovery.py:136: FutureWarning: The drivers ['geojson', 'postgis', 'shapefile', 'spatialite'] do not specify entry_points and were only discovered via a package scan. This may break in a future release of intake. The packages should be updated.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import intake\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from explore_utils import get_cmip6_catalogue\n",
    "from extract_utils import find_overlap_models, rename_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which datasets are required by populating these lists with details\n",
    "dset_name, exp, var, table_id, grid_label = [], [], [], [], []\n",
    "\n",
    "# Select name for this clollection of inputs\n",
    "collection_name = 'historical'\n",
    "#collection_name = 'piControl'\n",
    "\n",
    "# 1. siconc\n",
    "dset_name.append('siconc')\n",
    "exp.append(collection_name)\n",
    "var.append('siconc')\n",
    "table_id.append('SImon')\n",
    "grid_label.append('gn')\n",
    "\n",
    "# 2. areacello\n",
    "dset_name.append('areacello')\n",
    "exp.append(collection_name)\n",
    "var.append('areacello')\n",
    "table_id.append('Ofx')\n",
    "grid_label.append('gn')\n",
    "\n",
    "# 3. tas\n",
    "dset_name.append('tas')\n",
    "exp.append(collection_name)\n",
    "var.append('tas')\n",
    "table_id.append('Amon')\n",
    "grid_label.append('gn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full catalogue of CMIP6 data on glade or cloud\n",
    "cmip6_collection = get_cmip6_catalogue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MPI-ESM1-2-LR', 'MIROC6', 'CESM2-FV2', 'NorESM2-LM', 'MPI-ESM-1-2-HAM', 'SAM0-UNICON', 'ACCESS-CM2', 'MPI-ESM1-2-HR', 'MIROC-ES2L', 'CESM2-WACCM-FV2', 'ACCESS-ESM1-5', 'CESM2', 'NorCPM1', 'CanESM5', 'CanESM5-CanOE', 'MRI-ESM2-0']\n"
     ]
    }
   ],
   "source": [
    "# Find where models contain all necessary variables\n",
    "models_intersect = find_overlap_models(dset_name, exp, var, table_id, grid_label, cmip6_collection)\n",
    "print(models_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dictionary of file names for speficied data\n",
    "dset_dict = {}\n",
    "for i in range(0, len(dset_name)):\n",
    "    dset_dict[dset_name[i]] = cmip6_collection.search(\n",
    "                                experiment_id=exp[i], table_id=table_id[i], \n",
    "                                variable_id=var[i], grid_label=grid_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siconc\n",
      "Progress: |███████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "             \n",
      "--> There are 31 group(s)\n",
      "areacello\n",
      "Progress: |███████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "             \n",
      "--> There are 24 group(s)\n",
      "tas\n",
      "Progress: |███████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "             \n",
      "--> There are 32 group(s)\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "for d in dset_dict.keys():\n",
    "    print(d)\n",
    "    dset_dict[d] = dset_dict[d].to_dataset_dict(zarr_kwargs={'consolidated': True, 'decode_times': True}, \n",
    "                                           cdf_kwargs={'chunks': {}, 'decode_times': True})\n",
    "    \n",
    "# Having some problems, times don't want to be decoded for picontrol. Might not be a problem but should investigate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename dimensions to i,j so they're consistent across variables\n",
    "dset_dict_temp = {}\n",
    "for d in dset_dict.keys():\n",
    "    dset_dict_temp[d] = {}\n",
    "    for m in dset_dict[d].keys():\n",
    "        dset_dict_temp[d][m] = rename_dimensions(dset_dict[d][m], dset_dict_temp)\n",
    "\n",
    "dset_dict = dset_dict_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making key of dataset model name\n",
    "dset_dict_temp = {}\n",
    "for d in dset_dict.keys():\n",
    "    dset_dict_temp[d] = {}\n",
    "    for key, item in dset_dict[d].items():\n",
    "        model = item.attrs['source_id']\n",
    "        if model in models_intersect:\n",
    "            dset_dict_temp[d][model] = item\n",
    "\n",
    "dset_dict = dset_dict_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding areacello and/or areacella as a variable in other datasets\n",
    "if 'areacello' in dset_dict.keys():\n",
    "    for d in dset_dict.keys(): # for each variable\n",
    "        for key in dset_dict[d].keys(): # for each model\n",
    "            # if table_id suggests variable is a sea ice or ocean variable, add areacello\n",
    "            if dset_dict[d][key].attrs['table_id'][0] in ['S', 'O']:\n",
    "                dset_dict[d][key]['areacello'] = dset_dict['areacello'][key]['areacello']\n",
    "\n",
    "if 'areacella' in dset_dict.keys():\n",
    "    for d in dset_dict.keys(): # for each variable\n",
    "        for key in dset_dict[d].keys(): # for each model\n",
    "            # if table_id suggests variable is an atmosphere variable, add areacella\n",
    "            if dset_dict[d][key].attrs['table_id'][0] in ['A']:\n",
    "                dset_dict[d][key]['areacella'] = dset_dict['areacella'][key]['areacella']                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-LR ['r8i1p1f1', 'r1i1p1f1', 'r6i1p1f1', 'r9i1p1f1', 'r5i1p1f1', 'r4i1p1f1', 'r10i1p1f1', 'r3i1p1f1', 'r2i1p1f1', 'r7i1p1f1']\n",
      "\n",
      "MIROC6 ['r8i1p1f1', 'r1i1p1f1', 'r6i1p1f1', 'r9i1p1f1', 'r5i1p1f1', 'r4i1p1f1', 'r10i1p1f1', 'r3i1p1f1', 'r2i1p1f1', 'r7i1p1f1']\n",
      "\n",
      "CESM2-FV2 ['r1i1p1f1']\n",
      "\n",
      "NorESM2-LM ['r2i1p1f1']\n",
      "\n",
      "MPI-ESM-1-2-HAM ['r1i1p1f1', 'r2i1p1f1']\n",
      "\n",
      "SAM0-UNICON ['r1i1p1f1']\n",
      "\n",
      "ACCESS-CM2 ['r1i1p1f1', 'r2i1p1f1']\n",
      "\n",
      "MPI-ESM1-2-HR ['r8i1p1f1', 'r1i1p1f1', 'r6i1p1f1', 'r9i1p1f1', 'r5i1p1f1', 'r4i1p1f1', 'r10i1p1f1', 'r3i1p1f1', 'r2i1p1f1', 'r7i1p1f1']\n",
      "\n",
      "MIROC-ES2L ['r3i1p1f2', 'r1i1p1f2', 'r2i1p1f2']\n",
      "\n",
      "CESM2-WACCM-FV2 ['r1i1p1f1']\n",
      "\n",
      "ACCESS-ESM1-5 ['r1i1p1f1', 'r2i1p1f1', 'r3i1p1f1']\n",
      "\n",
      "CESM2 ['r8i1p1f1', 'r6i1p1f1', 'r11i1p1f1', 'r1i1p1f1', 'r9i1p1f1', 'r5i1p1f1', 'r10i1p1f1', 'r3i1p1f1', 'r4i1p1f1', 'r2i1p1f1', 'r7i1p1f1']\n",
      "\n",
      "NorCPM1 ['r26i1p1f1', 'r23i1p1f1', 'r17i1p1f1', 'r24i1p1f1']\n",
      "\n",
      "CanESM5 ['r8i1p1f1', 'r13i1p1f1', 'r13i1p2f1', 'r11i1p1f1', 'r7i1p2f1', 'r21i1p2f1', 'r5i1p1f1', 'r20i1p1f1', 'r4i1p1f1', 'r8i1p2f1', 'r19i1p2f1', 'r18i1p2f1', 'r5i1p2f1', 'r22i1p2f1', 'r12i1p1f1', 'r15i1p1f1', 'r19i1p1f1', 'r20i1p2f1', 'r16i1p1f1', 'r4i1p2f1', 'r17i1p1f1', 'r14i1p1f1', 'r7i1p1f1', 'r21i1p1f1', 'r22i1p1f1', 'r1i1p1f1', 'r18i1p1f1', 'r2i1p2f1', 'r10i1p1f1', 'r3i1p1f1', 'r1i1p2f1', 'r17i1p2f1', 'r6i1p2f1', 'r12i1p2f1', 'r14i1p2f1', 'r10i1p2f1', 'r6i1p1f1', 'r15i1p2f1', 'r23i1p2f1', 'r9i1p2f1', 'r24i1p2f1', 'r9i1p1f1', 'r3i1p2f1', 'r11i1p2f1', 'r23i1p1f1', 'r2i1p1f1', 'r25i1p1f1', 'r16i1p2f1', 'r25i1p2f1', 'r24i1p1f1']\n",
      "\n",
      "CanESM5-CanOE ['r1i1p2f1', 'r2i1p2f1', 'r3i1p2f1']\n",
      "\n",
      "MRI-ESM2-0 ['r1i1p1f1', 'r5i1p1f1', 'r4i1p1f1', 'r3i1p1f1', 'r2i1p1f1']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure only ensemble members that overlap all data sets are included\n",
    "dset_dict_temp = {}\n",
    "\n",
    "for d in dset_dict.keys():\n",
    "    dset_dict_temp[d] = {}\n",
    "    \n",
    "for m in models_intersect:\n",
    "    ems = [0]\n",
    "    for d in dset_dict.keys():\n",
    "        dset_dict_temp[d][m] = {}\n",
    "        if d is not 'areacello':\n",
    "            if ems[0]==0:\n",
    "                ems = dset_dict[d][m]['member_id'].values\n",
    "            else:\n",
    "                ems = list(set(ems) & set(dset_dict[d][m]['member_id'].values))\n",
    "    \n",
    "    for d in dset_dict.keys():                       \n",
    "        dset_dict_temp[d][m] = dset_dict[d][m].sel(member_id=ems)\n",
    "        \n",
    "    print(m, ems)\n",
    "    print()\n",
    "        \n",
    "dset_dict = dset_dict_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionaries for future use\n",
    "save_flag = True\n",
    "if save_flag:\n",
    "    if dset_dict:\n",
    "        np.save('dset_dict_' + collection_name + '.npy', dset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do\n",
    "#1. add something for selecting specific time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
